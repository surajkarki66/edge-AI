{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5bf5be1eb1084c3f94ccf0430b3200e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da6d29712456488585add087953fe2dd",
              "IPY_MODEL_d9f7a69d8adf4cc3bc6793dc2f23f489",
              "IPY_MODEL_bff94f1e04b64f8cb1022f5ea89f86bd"
            ],
            "layout": "IPY_MODEL_6992b95a66ac49ad949f0528ef5b3aa6"
          }
        },
        "da6d29712456488585add087953fe2dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ca6a5d60c144c02a982117adb0ecee6",
            "placeholder": "​",
            "style": "IPY_MODEL_86b4790c3f4c4b0f85b34b899f5dca6f",
            "value": "config.json: 100%"
          }
        },
        "d9f7a69d8adf4cc3bc6793dc2f23f489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c572c038fe114fcda0935e86a5d80206",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_348238432ada489ea972a23585d913f5",
            "value": 570
          }
        },
        "bff94f1e04b64f8cb1022f5ea89f86bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66ec0b72da4f44aaa569ce5399fbd235",
            "placeholder": "​",
            "style": "IPY_MODEL_5758267018d14e8a82d5974636cefa9f",
            "value": " 570/570 [00:00&lt;00:00, 56.2kB/s]"
          }
        },
        "6992b95a66ac49ad949f0528ef5b3aa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ca6a5d60c144c02a982117adb0ecee6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86b4790c3f4c4b0f85b34b899f5dca6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c572c038fe114fcda0935e86a5d80206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "348238432ada489ea972a23585d913f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66ec0b72da4f44aaa569ce5399fbd235": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5758267018d14e8a82d5974636cefa9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2013fe9b465417bab1c204d217d2e36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_525c9ad0f69a4a18808e53010a60f3df",
              "IPY_MODEL_cd922eed561d49e2b949366fc35e34ea",
              "IPY_MODEL_c9d7c374e0594878aa4f54ebb326492d"
            ],
            "layout": "IPY_MODEL_74b934f752014c9cb98b609be9229132"
          }
        },
        "525c9ad0f69a4a18808e53010a60f3df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbef36810f3548ae86731840c12e605f",
            "placeholder": "​",
            "style": "IPY_MODEL_2f527c0f8a804acf9ddaa1af8a7bbbf6",
            "value": "model.safetensors: 100%"
          }
        },
        "cd922eed561d49e2b949366fc35e34ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af08d33d429c41c59db084b071f0504d",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e125863333446fe89bdf77e63745a94",
            "value": 440449768
          }
        },
        "c9d7c374e0594878aa4f54ebb326492d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_910d7c723a014f33ae903e3541a4126a",
            "placeholder": "​",
            "style": "IPY_MODEL_2a2e4fedb9b74eb58268006c81b23124",
            "value": " 440M/440M [00:06&lt;00:00, 48.2MB/s]"
          }
        },
        "74b934f752014c9cb98b609be9229132": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbef36810f3548ae86731840c12e605f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f527c0f8a804acf9ddaa1af8a7bbbf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af08d33d429c41c59db084b071f0504d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e125863333446fe89bdf77e63745a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "910d7c723a014f33ae903e3541a4126a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a2e4fedb9b74eb58268006c81b23124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How To Succeed With PyTorch Quantization\n",
        "Optimizing models for deployment on edge devices or in low-resource environments is essential. PyTorch Quantization plays a crucial role by reducing model size and improving inference speed, all while preserving accuracy. It’s a key enabler for AI applications, from IoT devices to faster cloud inference.\n",
        "\n",
        "However, achieving success with PyTorch Quantization involves more than just using a few built-in APIs. While dynamic quantization, static quantization, and quantization-aware training offer powerful capabilities, they also present challenges—such as accuracy loss, debugging complexity, and compatibility issues.\n",
        "\n",
        "This notebook goes beyond the basics. It’s a hands-on guide to effectively using PyTorch Quantization in real-world scenarios. We’ll explore common challenges and share strategies to overcome them, helping you build optimized, reliable AI solutions."
      ],
      "metadata": {
        "id": "5i5CdCRXzBb8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Applications Of PyTorch Quantization\n",
        "PyTorch Quantization is a key technology for deploying AI models in resource-constrained environments where low latency and energy efficiency are crucial. By shrinking model size and accelerating inference, it enables practical, high-performance AI solutions across diverse real-world applications.\n",
        "\n",
        "### Edge AI & IoT Devices\n",
        "Quantization is crucial for deploying deep learning models on edge devices such as smartphones, IoT sensors, and embedded systems. For example, applying static quantization to an object detection model can significantly speed up frame processing on a mobile GPU, enabling real-time performance."
      ],
      "metadata": {
        "id": "Cgit6H0RzZ4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.quantization as quant\n",
        "from torchvision.models import resnet18\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os"
      ],
      "metadata": {
        "id": "KDcG9zO7zW9X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained model\n",
        "model_fp32 = resnet18(pretrained=True)\n",
        "model_fp32.eval()\n",
        "\n",
        "# Save original model to check size\n",
        "torch.save(model_fp32.state_dict(), \"resnet18_fp32.pth\")\n",
        "fp32_size = os.path.getsize(\"resnet18_fp32.pth\") / 1e6  # in MB\n",
        "print(f\"Original model size (FP32): {fp32_size:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weqQnIp10aub",
        "outputId": "59882a73-98a4-4963-c986-8152b7900acd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model size (FP32): 46.84 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply dynamic quantization (note: static quantization requires calibration step)\n",
        "quantized_model = quant.quantize_dynamic(model_fp32, {torch.nn.Linear}, dtype=torch.qint8) # quantization on Linear Layer"
      ],
      "metadata": {
        "id": "cx9FvQM90vj8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save quantized model to check size\n",
        "torch.save(quantized_model.state_dict(), \"resnet18_quantized.pth\")\n",
        "quantized_size = os.path.getsize(\"resnet18_quantized.pth\") / 1e6  # in MB\n",
        "print(f\"Quantized model size: {quantized_size:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iElxjhce0zXq",
        "outputId": "24d42c2f-f981-43ae-be94-5fc9aaf7d21c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized model size: 45.30 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick functional check with a dummy input image\n",
        "# Load and preprocess a sample image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])"
      ],
      "metadata": {
        "id": "tXh8v0vN02Bc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a sample image (you can replace this with any local image path)\n",
        "from urllib.request import urlopen\n",
        "from io import BytesIO\n",
        "\n",
        "url = \"https://github.com/pytorch/hub/raw/master/images/dog.jpg\"\n",
        "image = Image.open(BytesIO(urlopen(url).read())).convert(\"RGB\")\n",
        "input_tensor = transform(image).unsqueeze(0)\n",
        "\n",
        "# Inference with quantized model\n",
        "with torch.no_grad():\n",
        "    output = quantized_model(input_tensor)\n",
        "\n",
        "# Display top-1 predicted class index\n",
        "_, predicted = torch.max(output, 1)\n",
        "print(f\"Predicted class index: {predicted.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0gRNAnc058m",
        "outputId": "44f7f92d-eb9a-49f6-a711-0bcb7114c906"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class index: 258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference with original model\n",
        "with torch.no_grad():\n",
        "    output = model_fp32(input_tensor)\n",
        "\n",
        "# Display top-1 predicted class index\n",
        "_, predicted = torch.max(output, 1)\n",
        "print(f\"Predicted class index: {predicted.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnLnUcki08ps",
        "outputId": "80716578-6887-42b9-b15a-f03ad111bea8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class index: 258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cloud Cost Optimization\n",
        "Quantized models use less memory and computing power, leading to lower costs for cloud-based inference. For example, dynamically quantizing a BERT model for NLP tasks can greatly reduce inference latency while maintaining accuracy."
      ],
      "metadata": {
        "id": "F8iK8m4k11Cn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accelerated Inference For Vision & NLP Models\n",
        "Quantization-aware training (QAT) helps maintain high accuracy in tasks like image classification and sequence modeling. It's especially useful in applications such as recommendation systems and chatbots, where fast, near-real-time responses are essential."
      ],
      "metadata": {
        "id": "sGtfjJUK2GcH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enhanced Performance For Embedded AI Applications\n",
        "In robotics and autonomous vehicles, where low latency and high throughput are critical, quantized models enable efficient processing of sensor data, allowing for quicker decision-making.\n",
        "\n",
        "These applications highlight how PyTorch Quantization empowers developers to bring AI to resource-constrained environments with minimal accuracy loss. However, careful preparation and fine-tuning are essential to fully realize its benefits."
      ],
      "metadata": {
        "id": "gnWiXVle2NDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenges & Pain Points In PyTorch Quantization\n",
        "Although PyTorch Quantization provides powerful tools for optimizing deep learning models, its implementation can come with challenges that disrupt workflows or affect model performance. Below are some of the common challenges and ways to address them:\n",
        "\n",
        "### 1. Accuracy Trade-offs\n",
        "One of the biggest challenges in PyTorch Quantization is the accuracy drop, particularly for models that are not inherently robust to reduced precision. Architectures with highly non-linear layers, like transformers, tend to experience more significant degradation when transitioning from FP32 to INT8 precision. To mitigate this issue, Quantization-Aware Training (QAT) can be used. QAT allows the model to be fine-tuned by simulating quantized operations during training, helping the model adapt to lower precision and maintain performance even after quantization."
      ],
      "metadata": {
        "id": "8YFApZ4e2k84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.quantization as quant\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "model.qconfig = quant.get_default_qat_qconfig('fbgemm')\n",
        "quant.prepare_qat(model)\n",
        "\n",
        "# Training loop to fine-tune\n",
        "quantized_model = quant.convert(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj8NaT4n2FfL",
        "outputId": "8ae1fc07-8f0b-4fbb-cd64-eab90d227a43"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Debugging & Model Validation\n",
        "Quantized models can be challenging to debug due to issues like mismatched scale/zero-point parameters, unexpected performance bottlenecks, or quantization errors. These challenges arise from the complexity of low-level details that are hidden behind quantization processes, which may not always be obvious during training or inference."
      ],
      "metadata": {
        "id": "652xh29M4EAx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Framework Limitations\n",
        "PyTorch Quantization has limitations in supporting custom layers or operators. Models with non-standard components may require manual handling to integrate quantization, leading to increased development time."
      ],
      "metadata": {
        "id": "ZMFKz8Pf4PO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.     Compatibility Challenges\n",
        "\n",
        "Deploying quantized models on various hardware platforms, particularly resource-constrained devices like mobile phones or older GPUs, can lead to compatibility issues. These challenges stem from differences in hardware capabilities, software frameworks, and the specific requirements of the deployment platform."
      ],
      "metadata": {
        "id": "XyCCIO_k4dsR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Tooling Gaps in PyTorch Quantization\n",
        "\n",
        "While PyTorch provides a solid foundation for quantization workflows, it lacks some advanced tools and features that can streamline the process of debugging and visualizing quantized models. This leaves developers with gaps that often require them to rely on external libraries and additional tools."
      ],
      "metadata": {
        "id": "YOlz74et4pcW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Practices for Success with PyTorch Quantization\n",
        "\n",
        "To get the most out of PyTorch Quantization and ensure your models are optimized for deployment in resource-constrained environments, follow these best practices. These strategies help mitigate common challenges, maintain model accuracy, and maximize performance:\n",
        "\n",
        "### 1. Choose The Right Quantization Type\n",
        "Understanding the use case is critical for selecting the appropriate quantization type -\n",
        "\n",
        "- Dynamic Quantization: Best for NLP models with fewer compute-intensive operations.\n",
        "\n",
        "- Static Quantization: Ideal for vision models where inference speed is crucial.\n",
        "\n",
        "- Quantization-Aware Training (QAT): Essential for recovering accuracy in edge cases.\n",
        "\n",
        "For example, to quantize a BERT model dynamically -"
      ],
      "metadata": {
        "id": "nbcsaPpl45Dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.quantization as quant\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "quantized_model = quant.quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280,
          "referenced_widgets": [
            "5bf5be1eb1084c3f94ccf0430b3200e4",
            "da6d29712456488585add087953fe2dd",
            "d9f7a69d8adf4cc3bc6793dc2f23f489",
            "bff94f1e04b64f8cb1022f5ea89f86bd",
            "6992b95a66ac49ad949f0528ef5b3aa6",
            "7ca6a5d60c144c02a982117adb0ecee6",
            "86b4790c3f4c4b0f85b34b899f5dca6f",
            "c572c038fe114fcda0935e86a5d80206",
            "348238432ada489ea972a23585d913f5",
            "66ec0b72da4f44aaa569ce5399fbd235",
            "5758267018d14e8a82d5974636cefa9f",
            "a2013fe9b465417bab1c204d217d2e36",
            "525c9ad0f69a4a18808e53010a60f3df",
            "cd922eed561d49e2b949366fc35e34ea",
            "c9d7c374e0594878aa4f54ebb326492d",
            "74b934f752014c9cb98b609be9229132",
            "fbef36810f3548ae86731840c12e605f",
            "2f527c0f8a804acf9ddaa1af8a7bbbf6",
            "af08d33d429c41c59db084b071f0504d",
            "9e125863333446fe89bdf77e63745a94",
            "910d7c723a014f33ae903e3541a4126a",
            "2a2e4fedb9b74eb58268006c81b23124"
          ]
        },
        "id": "mD-A78hS3BN-",
        "outputId": "aa0ebd7b-2030-4dff-ad66-f66048d9b04e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bf5be1eb1084c3f94ccf0430b3200e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2013fe9b465417bab1c204d217d2e36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Prepare The Model For Quantization\n",
        "Fusing layers (e.g., Conv2d + BatchNorm) helps reduce computational overhead and improves performance."
      ],
      "metadata": {
        "id": "Exh91nmA6mwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Calibrate With Representative Data\n",
        "For static quantization, calibration is crucial to determine optimal scale and zero-point values. Always use representative datasets to calibrate the model.\n",
        "\n",
        "### 4. Leverage Quantization-Aware Training (QAT)\n",
        "When accuracy and loss is unacceptable, QAT can help fine-tune the model.\n",
        "- Prepare the model for QAT.\n",
        "- Train with simulated quantized operations.\n",
        "- Convert the trained model to a fully quantized version.\n",
        "    \n",
        "    \n",
        "### 5. Monitor Performance Metrics\n",
        "Evaluate metrics like latency, throughput, and memory usage on the target hardware. PyTorch’s torch.utils.benchmark library can help track improvements.\n",
        "\n",
        "### 6. Iterate & Fine-Tune\n",
        "Quantization isn’t a one-size-fits-all approach. It requires experimentation and fine-tuning, particularly when using QAT or custom configurations, to strike the right balance between performance and accuracy.\n",
        "\n",
        "By implementing these best practices, teams have successfully navigated PyTorch Quantization workflows, tackled common challenges, and reaped the advantages of smaller model sizes and faster inference speeds."
      ],
      "metadata": {
        "id": "AulpsiHl62Yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "u6X9dihI6yeG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}