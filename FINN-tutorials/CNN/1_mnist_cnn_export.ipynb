{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afff1419-118a-4018-9d51-c4a122755f29",
   "metadata": {},
   "source": [
    "# FINN - End-to-End Flow\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "In this experiment, we will show how to take a simple, binarized, fully-connected network trained on the MNIST data set and take it all the way down to a customized bitfile running on a PYNQ board. \n",
    "\n",
    "In this notebook, we will export the brevitas model as .onnx file.\n",
    "\n",
    "## 1. Brevitas export <a id='brev_exp'></a>\n",
    "FINN expects an ONNX model as input. This can be a model trained with [Brevitas](https://github.com/Xilinx/brevitas). Brevitas is a PyTorch library for quantization-aware training and the FINN Docker image comes with several [example Brevitas networks](https://github.com/Xilinx/brevitas/tree/master/src/brevitas_examples/bnn_pynq). To show the FINN end-to-end flow, we'll use the TFC-w1a1 model as example network.\n",
    "\n",
    "First a few things have to be imported. Then the model can be loaded with the pretrained weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef55eaa8-b164-43fe-98a6-32a896b3ba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnx\n",
    "\n",
    "\n",
    "from finn.util.test import get_test_model_trained\n",
    "from finn.util.visualization import showSrc, showInNetron\n",
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a41a004-cfbf-434d-9134-40354d00bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_dir = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53967db2-36c0-407d-a6fc-5037fdfea220",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfc = get_test_model_trained(\"TFC\", 1, 1)\n",
    "export_onnx_path = build_dir + \"/tfc_w1_a1.onnx\"\n",
    "export_qonnx(tfc, torch.randn(1, 1, 28, 28), build_dir + \"/tfc_w1_a1.onnx\"); # semicolon added to suppress log\n",
    "qonnx_cleanup(export_onnx_path, out_file=export_onnx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b37180-809a-4bb9-a5ea-1f875688f70c",
   "metadata": {},
   "source": [
    "The model was now exported in QONNX format, loaded with the pretrained weights and saved under the name \"tfc_w1_a1.onnx\".\n",
    "To visualize the exported model, Netron can be used. Netron is a visualizer for neural networks and allows interactive investigation of network properties. For example, you can click on the individual nodes and view the properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ebcc293-b7f4-43cb-88d1-afbfb2d4ba3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serving './/tfc_w1_a1.onnx' at http://0.0.0.0:2222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:2222/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f7a1c38f580>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir + \"/tfc_w1_a1.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb85286-16ef-4178-97d7-597ba42995c4",
   "metadata": {},
   "source": [
    "Now that we have the model in .onnx format, we can work with it using FINN. For that, `ModelWrapper` is used. It is a wrapper around the ONNX model which provides several helper functions to make it easier to work with the model. `ModelWrapper` is imported from the [QONNX repo](https://github.com/fastmachinelearning/qonnx), this repository contains several functionality that is used in FINN. The model was exported in QONNX format, to feed it into the FINN flow, our first step is to convert it to the FINN-ONNX format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9406919b-0194-4cbb-9f3a-5d17671352a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "\n",
    "model = ModelWrapper(build_dir + \"/tfc_w1_a1.onnx\")\n",
    "model = model.transform(ConvertQONNXtoFINN())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13294172-02e0-42ec-aff8-f8c4c44af2dd",
   "metadata": {},
   "source": [
    "After the conversion we save the model and visualize it using Netron. As you can see, quantization is now expressed differently. Where we had Quant nodes before, there are now MultiThreshold nodes present in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d018146d-9ea8-4f7e-96ad-0159264c2ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serving './/tfc_w1_a1_finn.onnx' at http://0.0.0.0:2222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:2222/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f7a15dcf070>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(build_dir + \"/tfc_w1_a1_finn.onnx\")\n",
    "showInNetron(build_dir + \"/tfc_w1_a1_finn.onnx\", port=2222)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8b6e9b-680e-4486-900d-84c1cff28120",
   "metadata": {},
   "source": [
    "Now the model is prepared and could be simulated using Python. How this works is described in the Jupyter notebook about verification and can be found [here](tfc_end2end_verification.ipynb#simpy).\n",
    "\n",
    "The model can now also be processed in different ways. The principle of FINN are **analysis and transformation passes**, which can be applied to the model. An analysis pass extracts specific information about the model and returns it to the user in the form of a dictionary. A transformation pass changes the model and returns the changed model back to the FINN flow.\n",
    "\n",
    "Since the goal in this notebook is to process the model to such an extent that a bitstream can be generated from it, the focus is on the transformations that are necessary for this. In the next section these are discussed in more detail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
